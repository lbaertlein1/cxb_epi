dplyr::mutate(values = purrr::map(questionnaireAnswers.agency, setNames, c("V1"))) %>%
unnest_wider(values)
table(temp$questionnaireAnswers.agency)
table(is.null(temp$questionnaireAnswers.agency))
temp1 <- temp %>% filter(!is.null(questionnaireAnswers.agency))
View(temp1)
temp$new_column <- sapply(temp[[1]], \(x) x[[1]]$value)
temp$agency <- sapply(temp$questionnaireAnswers.agency,"[[",1)
temp$questionnaireAnswers.agency[[1]]
temp$questionnaireAnswers.agency[[2]]
temp$questionnaireAnswers.agency[[200]]
temp$questionnaireAnswers.agency[[205]]
temp$questionnaireAnswers.agency[[2000]]
temp <- temp %>% mutate(agency = questionnaireAnswers.agency[[row_number()]])
agency <- temp$questionnaireAnswers.agency[[row_number()]])
agency <- temp$questionnaireAnswers.agency[[row_number()]]
lapply(temp$questionnaireAnswers.agency, `[[`, 1)
unlist(temp$questionnaireAnswers.agency)[ c(TRUE,FALSE) ]
agency <- unlist(temp$questionnaireAnswers.agency)[ c(TRUE,FALSE) ]
table(agency)
View(cases)
table(agency, exclude=NULL)
table(cases$agency)
cases <- cases %>% mutate(agency = substr(visualId, 1, 6))
table(cases$visualId)
table(cases$agency)
pacman::p_load(httr, readr, tidyverse, lubridate)
init_kobo_data_struc <- function(folder, base_url, username, password){
#check to see if folder exists, if not create it
if(!dir.exists(folder)){
dir.create(folder)
}
#check to see if cache directory exists, if not create it
cache_dir <- file.path(folder, "cache_dir")
if(!dir.exists(cache_dir)){
dir.create(cache_dir)
}
#Get Token
install.packages("remotes")
remotes::install_gitlab("dickoa/robotoolbox")
library("robotoolbox")
token <- kobo_token(username = username, password = password,
url = base_url)
#create specs yaml
specs_yaml <- file.path(folder,'cache_dir','specs.yaml')
if(!file.exists(specs_yaml)){
yaml_out <- list()
yaml_out$kobo$base_url <- base_url
yaml_out$kobo$username <- username
yaml_out$kobo$password <- password
yaml_out$kobo$token <- token
yaml_out$kobo_folder <- folder
write_yaml(yaml_out, specs_yaml)
}
Sys.setenv("kobo_folder" = folder)
Sys.setenv("base_url" = base_url)
kobo_settings()
}
## Load parameters from yaml
load_specs <- function(folder = Sys.getenv("kobo_folder")){
specs <- read_yaml(file.path(folder,'cache_dir','specs.yaml'))
return(specs)
}
#Select asset and download
getKOBO <- function(asset_id = NULL,
get_all_cebs = FALSE,
get_all = FALSE){
if(!is.null(asset_id)){
l <- kobo_asset_list() %>%
arrange(desc(as.Date(date_modified, origin=lubridate::origin))) %>%
select(uid, name) %>%
filter(!is.na(name) & name != "")
selection <- l %>%
filter(uid %in% asset_id)
asset_id <- selection$uid
asset_name <- selection$name
}
if(is.null(asset_id) & get_all_cebs == FALSE & get_all == FALSE){
l <- kobo_asset_list() %>%
arrange(desc(as.Date(date_modified, origin=lubridate::origin))) %>%
select(uid, name) %>%
filter(!is.na(name) & name != "")
selection <- l %>%
filter(name == l$name[utils::menu(l$name, title="Select an Asset:")])
asset_id <- selection$uid
asset_name <- selection$name
}
if(get_all_cebs == TRUE & get_all == FALSE){
asset_id <- c("acfGrxnmkTaFvSTdHnrQ3x", "a9bYeVttuVuSzCcgmk9qpo", "a4V5jXFEHjwALe8ztWQNvX", "a6GKjVvR7dyEPeXDtQ9U37", "a5BCfuooic3qN8Y27pR44M")
l <- kobo_asset_list() %>%
arrange(desc(as.Date(date_modified, origin=lubridate::origin))) %>%
select(uid, name) %>%
filter(!is.na(name) & name != "")
selection <- l %>%
filter(uid %in% asset_id)
asset_id <- selection$uid
asset_name <- selection$name
}
if(get_all == TRUE){
selection <- kobo_asset_list() %>%
arrange(desc(as.Date(date_modified, origin=lubridate::origin))) %>%
select(uid, name) %>%
filter(!is.na(name) & name != "")
asset_id <- selection$uid
asset_name <- selection$name
}
output_list <- list()
for(i in 1:length(asset_id)){
data <- kobo_data(kobo_asset(asset_id[i]))
output_list <- append(output_list, list(new=data))
names(output_list)[i] <- asset_name[i]
}
return(output_list)
}
init_kobo_data_struc(folder = "C:/Users/balukhali-epidem/Documents/Kobo_Data"
base_url = "https://kobo.msf.org/"
username = "cxb_epi_data"
password = "CXB_EAT_MRT_1971")
init_kobo_data_struc(folder = "C:/Users/balukhali-epidem/Documents/Kobo_Data",
base_url = "https://kobo.msf.org/",
username = "cxb_epi_data",
password = "CXB_EAT_MRT_1971")
data <- getKOBO(asset_id = NULL,
get_all_cebs = TRUE,
get_all = FALSE)
pacman::p_load(yaml)
init_kobo_data_struc(folder = "C:/Users/balukhali-epidem/Documents/Kobo_Data",
base_url = "https://kobo.msf.org/",
username = "cxb_epi_data",
password = "CXB_EAT_MRT_1971")
data <- getKOBO(asset_id = NULL,
get_all_cebs = TRUE,
get_all = FALSE)
View(data)
verification <- data[1]
View(verification)
verification <- data[[1]
]
View(verification)
temp <- verification$_id == "AWD220153"
temp <- verification %>% filter(alertid_illness == "AWD220153")
temp <- verification %>% filter(block == "C3)
temp <- verification %>% filter(block == "C3")
temp <- verification %>% filter(grepl("c3", block, ignore.case=TRUE)
)
temp <- verification %>% filter(grepl("c-3", block, ignore.case=TRUE))
View(temp)
temp <- verification %>% filter(camp == "5")
temp <- verification %>% filter(camp == "5")
verification <- verification %>% janitor::clean_names()
View(verification)
colnames(verification)
var_label(verification)
install.packages("labelled")
library(labelled)
remove_labels(verification)
verification <- remove_labels(verification)
View(verification)
class(verification)
verification <- as.data.frame(verification)
class(verification)
View(verification)
source('~/GitHub/cxb_epi/GetKOBO/utils.R')
View(data)
name <- name(data[[1]])
name <- names(data[[1]])
daily_signal_tally <- data$`0_Daily signal tally`
daily_signal_tally <- remove_labels(as.data.frame(data$`0_Daily signal tally`))
class(daily_signal_tally)
signal_verification <- remove_labels(as.data.frame(data$`1_Signal verification`))
field_assessment <- remove_labels(as.data.frame(data$`2_Field_assessment`))
risk_assessment <-  remove_labels(as.data.frame(data$`3_Risk assessment`))
response  <- remove_labels(as.data.frame(data$`4_Response`))
daily_signal_tally <- remove_labels(as.data.frame(data$`0_Daily signal tally`)) %>%
janitor::clean_names()
signal_verification <- remove_labels(as.data.frame(data$`1_Signal verification`)) %>%
janitor::clean_names()
field_assessment <- remove_labels(as.data.frame(data$`2_Field_assessment`)) %>%
janitor::clean_names()
risk_assessment <-  remove_labels(as.data.frame(data$`3_Risk assessment`)) %>%
janitor::clean_names()
response  <- remove_labels(as.data.frame(data$`4_Response`)) %>%
janitor::clean_names()
View(response)
View(risk_assessment)
table(risk_assessment$ra_date)
table(risk_assessment$ra_date, risk_assessment$risk_classification)
table(risk_assessment$ra_date, risk_assessment$alert)
table(risk_assessment$risk_classification, risk_assessment$alert)
View(field_assessment)
source('~/GitHub/cxb_epi/GetKOBO/utils.R')
init_kobo_data_struc(folder = "C:/Users/balukhali-epidem/Documents/Kobo_Data",
base_url = "https://kobo.msf.org/",
username = "cxb_epi_data",
password = "CXB_EAT_MRT_1971")
cebs_data <- getKOBO(asset_id = NULL,
get_all_cebs = TRUE,
get_all = FALSE)
pacman::p_load(labelled)
daily_signal_tally <- remove_labels(as.data.frame(data$`0_Daily signal tally`)) %>%
janitor::clean_names()
signal_verification <- remove_labels(as.data.frame(data$`1_Signal verification`)) %>%
janitor::clean_names()
field_assessment <- remove_labels(as.data.frame(data$`2_Field_assessment`)) %>%
janitor::clean_names()
risk_assessment <-  remove_labels(as.data.frame(data$`3_Risk assessment`)) %>%
janitor::clean_names()
response  <- remove_labels(as.data.frame(data$`4_Response`)) %>%
janitor::clean_names()
source('~/GitHub/cxb_epi/GetKOBO/utils.R')
init_kobo_data_struc(folder = "C:/Users/balukhali-epidem/Documents/Kobo_Data",
base_url = "https://kobo.msf.org/",
username = "cxb_epi_data",
password = "CXB_EAT_MRT_1971")
cebs_data <- getKOBO(asset_id = NULL,
get_all_cebs = TRUE,
get_all = FALSE,
with_labels = FALSE)
View(cebs_data)
cebs_data[["2_Field_assessment"]]
source('~/GitHub/cxb_epi/GetKOBO/utils.R')
source('~/GitHub/cxb_epi/GetKOBO/utils.R')
cebs_data <- getKOBO(asset_id = NULL,
get_all_cebs = FALSE,
get_all = FALSE,
with_labels = FALSE)
data <- cebs_data$`Dengue Fever`
View(cebs_data)
source('~/GitHub/cxb_epi/GetDHIS2/utils.R')
init_dhis2_data_struc(folder = "C:/Users/balukhali-epidem/Documents/DHIS2_Data",
base_url = "https://his.oca.msf.org/",
username = "cxb-epidem",
password = "3p1d3m@Cxb")
pacman::p_load(yaml, tidyverse)
init_dhis2_data_struc(folder = "C:/Users/balukhali-epidem/Documents/DHIS2_Data",
base_url = "https://his.oca.msf.org/",
username = "cxb-epidem",
password = "3p1d3m@Cxb")
metadata <- getMetadata_all()
pacman::p_load(yaml, tidyverse, httr)
metadata <- getMetadata_all()
View(metadata)
View(metadata$eventReports)
metadata$eventReports[[1]]
View(metadata$eventReports[[1]])
metadata$eventReports[[1]][["href"]]
metadata$eventReports[[146]]
metadata[["eventFilters"]]
metadata[["programStages"]]
metadata[["categories"]]
metadata[["minMaxDataElements"]]
metadata$eventReports[[139]]
metadata[["eventReports"]]
metadata[["programs"]]
metadata[["dashboardItems"]]
country = "Bangladesh"
country_id <- rbindlist(map(metadata[["organisationUnits"]], as.data.table), fill = TRUE, idcol = T) %>%
filter(name == country & level == "3") %>%
select(id) %>%
unique()
pacman::p_load(yaml, tidyverse, httr, data.table)
country_id <- rbindlist(map(metadata[["organisationUnits"]], as.data.table), fill = TRUE, idcol = T) %>%
filter(name == country & level == "3") %>%
select(id) %>%
unique()
project_list <-  rbindlist(map(metadata[["organisationUnits"]], as.data.table), fill = TRUE, idcol = T) %>%
filter(level == "4" & grepl(country_id$id[1], path) & name != "_Geolocations") %>%
select(name, id) %>%
unique()
View(project_list)
org_unit_list <- rbindlist(map(metadata[["organisationUnits"]], as.data.table), fill = TRUE, idcol = T) %>%
filter(as.numeric(level) == 5 & grepl(paste0(project_list$id, collapse="|"), path) & name != "_Geolocations") %>%
select(name, id) %>%
unique()
#login to DHIS2
datimutils::loginToDATIM(
base_url = load_specs()$dhis2$base_url,
username = load_specs()$dhis2$username,
password = load_specs()$dhis2$password
)
pacman::p_load(yaml, tidyverse, httr, data.table, datimutils)
install.packages("https://github.com/pepfar-datim/datimutils")
install.packages("remotes")
remotes::install_github("pepfar-datim/datimutils")
#login to DHIS2
datimutils::loginToDATIM(
base_url = load_specs()$dhis2$base_url,
username = load_specs()$dhis2$username,
password = load_specs()$dhis2$password
)
data_elements <-  rbindlist(map(metadata[["dataElements"]], as.data.table), fill = TRUE, idcol = T) %>%
select(id, name, aggregationType) %>%
unique() %>%
rename(dataElements = id)
View(data_elements)
event_data_elements <-  rbindlist(map(metadata[["dataElements"]], as.data.table), fill = TRUE, idcol = T) %>%
select(id, name, aggregationType) %>%
unique() %>%
rename(dataElements = id) %>%
filter(aggregationType == "NONE")
View(org_unit_list)
org_unit_list <- org_unit_list[[3]]
org_unit_list <- org_unit_list[3]
time_period_type = "MONTHS",
start_date = "2020-01-01",
end_date = Sys.Date()
time_period_type = "MONTHS"
start_date = "2020-01-01"
end_date = Sys.Date()
event_data_elements$dataElements
time_period_type = "MONTHS"
start_date = "2020-01-01"
end_date = Sys.Date()
for(i in 1:length(event_data_elements$dataElements)){
print(i)
data <- tryCatch({
datimutils::getAnalytics(dx = event_data_elements$dataElements[i],
ou = dput(org_unit_list$id),
pe = dput(time_period),
return_names = TRUE)
}, error = function(e) {
NULL
})
if(i == 1){
all_data <- data
}
if(i != 1){
all_data <- all_data %>%
bind_rows(data)
}
}
relative_time_period = "LAST_12_MONTHS"
for(i in 1:length(event_data_elements$dataElements)){
print(i)
data <- tryCatch({
datimutils::getAnalytics(dx = event_data_elements$dataElements[i],
ou = dput(org_unit_list$id),
pe = dput("LAST_12_MONTHS"),
return_names = TRUE)
}, error = function(e) {
NULL
})
if(i == 1){
all_data <- data
}
if(i != 1){
all_data <- all_data %>%
bind_rows(data)
}
}
View(all_data)
i <- 10
print(i)
data <- tryCatch({
datimutils::getAnalytics(dx = event_data_elements$dataElements[i],
ou = dput(org_unit_list$id),
pe = dput("LAST_12_MONTHS"),
return_names = TRUE)
}, error = function(e) {
NULL
})
View(event_data_elements)
datimutils::getAnalytics(dx = event_data_elements$dataElements[i],
ou = dput(org_unit_list$id),
pe = dput("LAST_12_MONTHS"),
verbose = TRUE,
return_names = TRUE)
View(metadata$eventReports)
event_data_elements <-  rbindlist(map(metadata[["eventReports"]], as.data.table), fill = TRUE, idcol = T)
View(event_data_elements)
event_data_elements <-  rbindlist(map(metadata[["eventReports"]], as.data.table), fill = TRUE, idcol = T) %>%
select(id, name, aggregationType)
event_data_elements <-  rbindlist(map(metadata[["eventReports"]], as.data.table), fill = TRUE, idcol = T) %>%
select(id, name)
event_data_elements <-  rbindlist(map(metadata[["eventReports"]], as.data.table), fill = TRUE, idcol = T) %>%
select(id, name) %>%
unique() %>%
rename(dataElements = id)
View(event_data_elements)
for(i in 1:length(event_data_elements$dataElements)){
print(i)
data <- tryCatch({
datimutils::getAnalytics(dx = event_data_elements$dataElements[i],
ou = dput(org_unit_list$id),
pe = dput("LAST_12_MONTHS"),
verbose = TRUE,
return_names = TRUE)
}, error = function(e) {
NULL
})
if(i == 1){
all_data <- data
}
if(i != 1){
all_data <- all_data %>%
bind_rows(data)
}
}
event_data_elements$dataElements[i]
data <- tryCatch({
datimutils::getAnalytics(dx = event_data_elements$dataElements[i],
ou = dput(org_unit_list$id),
pe = dput("LAST_12_MONTHS"),
verbose = TRUE,
return_names = TRUE)
}, error = function(e) {
NULL
})
datimutils::getDataElements(values = event_data_elements$dataElements,
by="id")
data <- tryCatch({
datimutils::getAnalytics(dx = event_data_elements$dataElements,
ou = dput(org_unit_list$id),
pe = dput("LAST_12_MONTHS"),
verbose = TRUE,
return_names = TRUE)
}, error = function(e) {
NULL
})
temp <- datimutils::getDataValueSets()
datasets <-  rbindlist(map(metadata[["dataSets"]], as.data.table), fill = TRUE, idcol = T) %>%
select(id, name) %>%
unique() %>%
rename(dataElements = id)
temp <- datimutils::getDataValueSets(variable_values = datasets$dataElements)
temp <- datimutils::getDataValueSets(variable_keys = datasets$dataElements, variable_values = datasets$dataElements)
temp <- datimutils::getDataValueSets()
View(datasets)
View(org_unit_list)
metadata$dataSetReport
View(event_data_elements)
View(org_unit_list)
remotes::install_github("mayerantoine/Rdhis2tracker")
rdhis2tracker::get_all_dataelements()
events <- rbindlist(map(metadata[["events"]], as.data.table), fill = TRUE, idcol = T) %>%
select(id, name) %>%
unique() %>%
rename(dataElements = id)
events <- rbindlist(map(metadata[["events"]], as.data.table), fill = TRUE, idcol = T)
View(org_unit_list)
all_event_data <- GET("https://his.oca.msf.org/api/events?paging=false")
View(all_event_data)
all_event_data <- content(GET("https://his.oca.msf.org/api/events?paging=false"))
View(all_event_data)
xml_child(all_event_data, 2)
xml_child(all_event_data, 1)
xml_attrs(all_event_data)
load_specs()$dhis$username
load_specs()
load_specs()$dhis2$username
all_event_data <- content(GET("https://his.oca.msf.org/api/events?paging=false", authenticate(username=load_specs()$dhis2$username,
password=load_specs()$dhis2$password)))
all_event_data <- content(GET("https://his.oca.msf.org/api/events?paging=false", authenticate(user=load_specs()$dhis2$username,
password=load_specs()$dhis2$password)))
View(all_event_data)
xml_child(all_event_data, 41)
project_list <-  rbindlist(map(all_event_data[["node"]], as.data.table), fill = TRUE, idcol = T)
event_data <-  rbindlist(map(all_event_data[["doc"]], as.data.table), fill = TRUE, idcol = T)
event_data <-  rbindlist(map(all_event_data, as.data.table), fill = TRUE, idcol = T)
event_data <-  rbindlist(map(all_event_data[[node]], as.data.table), fill = TRUE, idcol = T)
event_data <-  rbindlist(map(all_event_data[["node"]], as.data.table), fill = TRUE, idcol = T)
View(org_unit_list)
all_event_data <- content(GET("https://his.oca.msf.org/api/events?&orgUnit=aBqPxoYSDpq", authenticate(user=load_specs()$dhis2$username,
password=load_specs()$dhis2$password)))
View(all_event_data)
xml_child(all_event_data, 48)
pacman::p_load(yaml, tidyverse, httr, data.table, xml2)
xml_child(all_event_data, 36)
all_event_data <- content(GET("https://his.oca.msf.org/api/events?&orgUnit=aBqPxoYSDpq", authenticate(user=load_specs()$dhis2$username,
password=load_specs()$dhis2$password)), as="parsed")
View(all_event_data)
xml_child(all_event_data, 3)
temp <- as.data.frame(xml_child(all_event_data, 3))
bind_rows(lapply(xml_attrs(all_event_data), function(x) data.frame(as.list(x), stringsAsFactors=FALSE)))
temp <- bind_rows(lapply(xml_attrs(all_event_data), function(x) data.frame(as.list(x), stringsAsFactors=FALSE)))
View(temp)
View(all_event_data)
temp <- bind_rows(lapply(xml_attrs(xml_child(all_event_data, 3)), function(x) data.frame(as.list(x), stringsAsFactors=FALSE)))
View(temp)
temp <- bind_rows(lapply(xml_attrs(all_event_data[[3]]), function(x) data.frame(as.list(x), stringsAsFactors=FALSE)))
temp <- bind_rows(lapply(xml_attrs(all_event_data[3]), function(x) data.frame(as.list(x), stringsAsFactors=FALSE)))
temp <- bind_rows(lapply(xml_attrs(all_event_data[1]), function(x) data.frame(as.list(x), stringsAsFactors=FALSE)))
temp <- bind_rows(lapply(xml_attrs(all_event_data), function(x) data.frame(as.list(x), stringsAsFactors=FALSE)))
links <- html_nodes(all_event_data, "a")
pacman::p_load(yaml, tidyverse, httr, data.table, xml2, rvest)
links <- html_nodes(all_event_data, "a")
links <- html_nodes(all_event_data)
links <- html_nodes(xml_child(all_event_data, 3))
xml_to_dataframe <- function(nodeset){
if(class(nodeset) != 'xml_nodeset'){
stop('Input should be "xml_nodeset" class')
}
lst <- lapply(nodeset, function(x){
tmp <- xml2::xml_text(xml2::xml_children(x))
names(tmp) <- xml2::xml_name(xml2::xml_children(x))
return(as.list(tmp))
})
result <- do.call(plyr::rbind.fill, lapply(lst, function(x)
as.data.frame(x, stringsAsFactors = F)))
return(dplyr::as.tbl(result))
}
sitemap_raw <-"https://his.oca.msf.org/api/events?&orgUnit=aBqPxoYSDpq"
sitemap <-read_xml(sitemap_raw)
sitemap <-all_event_data
sitemap_nodeset <- xml_children(sitemap)
sitemap_df <- xml_to_dataframe(sitemap_nodeset)
View(sitemap_df)
wqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-syncwqlAwsQUujLMetadata syncRobot_field-sync
length()
length(unique(sitemap_df$dataValues))
unique(site_map_df$dataValues)
unique(sitemap_df$dataValues)
